name: Daily Catholic Readings Scraper

on:
  schedule:
    - cron: "0 3 * * *" # Runs every day at 03:00 UTC (adjust as needed)
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape_readings:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set Up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install Dependencies
        run: |
          pip install selenium beautifulsoup4
          sudo apt-get install -y chromium-chromedriver
          echo 'CHROMEDRIVER_PATH="/usr/bin/chromedriver"' >> $GITHUB_ENV
          echo 'GOOGLE_CHROME_BIN="/usr/bin/google-chrome"' >> $GITHUB_ENV

      - name: Run Scraper
        run: python scrape.py # Ensure your scraper script is named `scrape.py`

      - name: Commit and Push Updated Readings
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add readings.json
          git commit -m "Updated daily readings"
          git push
        continue-on-error: true # Prevent failures if no changes were made
